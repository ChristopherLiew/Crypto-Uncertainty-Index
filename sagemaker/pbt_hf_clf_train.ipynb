{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc332e62",
   "metadata": {},
   "source": [
    "## Population Based Training for Hedge Classifier with Transformers\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5035bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Crypto-Uncertainty-Index/sagemaker\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c499aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Crypto-Uncertainty-Index\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280ea4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[tune] in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.10.0)\n",
      "Requirement already satisfied: emoji in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.7.0)\n",
      "Requirement already satisfied: arrow in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: tokenizers in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (0.11.6)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.18.4)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (11.2.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.19.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: wandb in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (0.12.11)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (20.3.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (1.0.2)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (3.19.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (3.4.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (0.8)\n",
      "Requirement already satisfied: redis>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (4.1.4)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (3.2.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (7.1.2)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (1.44.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (2.26.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (2.5)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]) (0.8.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from arrow) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from arrow) (4.0.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.17.0)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (2022.1.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from rich) (0.9.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from rich) (0.4.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from rich) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: setproctitle in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (1.5.7)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->ray[tune]) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->ray[tune]) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->ray[tune]) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->ray[tune]) (2.0.9)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema->ray[tune]) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema->ray[tune]) (0.17.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.12.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ray[tune]\" emoji arrow transformers tokenizers datasets sklearn rich numpy pandas wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29fb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.hedge_classifier.huggingface.pbt_transformer import (\n",
    "    train_pbt_hf_clf,\n",
    "    WANDB_DEFAULT_ARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719141dd",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d493e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vinai/bertweet-base\"\n",
    "train_data_dir = \"nlp/hedge_classifier/data/wiki_weasel_clean\"\n",
    "model_save_dir = \"nlp/hedge_classifier/models\"\n",
    "num_labels = 2\n",
    "text_col = \"text\"\n",
    "wandb_args = WANDB_DEFAULT_ARGS\n",
    "train_data_file_type = \"csv\"\n",
    "sample_data_size = 1000\n",
    "# Using A100\n",
    "num_cpus_per_trial = 8\n",
    "num_gpus_per_trial = 1\n",
    "smoke_test = False\n",
    "ray_address = None\n",
    "ray_num_trials = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6978dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: /home/ec2-user/.netrc\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# To be Removed (Don't leave your pw lying around :/ )\n",
    "wandb login 310cbf1480e4106c80f5c34995e7006f193319fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994d764",
   "metadata": {},
   "source": [
    "### Run PBT Hyperparams Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84eeab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2022-03-08 18:22:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Setting up Ray Tune                          <a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hf_finetune.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#83\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">83</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[2022-03-08 18:22:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Setting up Ray Tune                          \u001b]8;id=541454;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\u001b\\\u001b[2mhf_finetune.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=639300;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#83\u001b\\\u001b[2m83\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2022-03-08 18:22:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Preparing Datasets                          <a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hf_finetune.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#105\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[2022-03-08 18:22:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Preparing Datasets                          \u001b]8;id=856028;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\u001b\\\u001b[2mhf_finetune.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=9992;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using custom data configuration                 <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">builder.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py#378\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">378</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         default-402b02fb86ce5093                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using custom data configuration                 \u001b]8;id=697371;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py\u001b\\\u001b[2mbuilder.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=927975;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py#378\u001b\\\u001b[2m378\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         default-402b02fb86ce5093                        \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Reusing dataset csv <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080\">/home/ec2-user/.cache/hugg</span> <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">builder.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py#531\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">531</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">ingface/datasets/csv/default-402b02fb86ce5093/0</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">.0.0/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">433e0ccc46f9880962cc2b12065189766fbb2bee57</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">a221866138fb9203c83519</span><span style=\"font-weight: bold\">)</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Reusing dataset csv \u001b[1m(\u001b[0m\u001b[35m/home/ec2-user/.cache/hugg\u001b[0m \u001b]8;id=139511;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py\u001b\\\u001b[2mbuilder.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=594870;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/builder.py#531\u001b\\\u001b[2m531\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35mingface/datasets/csv/default-402b02fb86ce5093/0\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35m.0.0/\u001b[0m\u001b[95m433e0ccc46f9880962cc2b12065189766fbb2bee57\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[95ma221866138fb9203c83519\u001b[0m\u001b[1m)\u001b[0m                         \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b52965669c4313837d07d192de9a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Tokenizing Datasets                         <a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hf_finetune.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#117\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Tokenizing Datasets                         \u001b]8;id=468058;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\u001b\\\u001b[2mhf_finetune.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=761581;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#117\u001b\\\u001b[2m117\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2022-03-08 18:22:06] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Loading cached processed dataset at <span style=\"color: #800080; text-decoration-color: #800080\">/hom</span> <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">arrow_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py#2327\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2327</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">e/ec2-user/.cache/huggingface/datasets/c</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">sv/default-402b02fb86ce5093/0.0.0/433e0c</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">cc46f9880962cc2b12065189766fbb2bee57a221</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">866138fb9203c83519/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">cache-b0d2b01f5961a5e</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">a.arrow</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[2022-03-08 18:22:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Loading cached processed dataset at \u001b[35m/hom\u001b[0m \u001b]8;id=48704;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b\\\u001b[2marrow_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=375397;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py#2327\u001b\\\u001b[2m2327\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35me/ec2-user/.cache/huggingface/datasets/c\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35msv/default-402b02fb86ce5093/0.0.0/433e0c\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35mcc46f9880962cc2b12065189766fbb2bee57a221\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35m866138fb9203c83519/\u001b[0m\u001b[95mcache-b0d2b01f5961a5e\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[95ma.arrow\u001b[0m                                  \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9659289b29384fa2a2ecf67693280d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2022-03-08 18:22:11] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Loading cached shuffled indices for      <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">arrow_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py#2937\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2937</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         dataset at <span style=\"color: #800080; text-decoration-color: #800080\">/home/ec2-user/.cache/hugging</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">face/datasets/csv/default-402b02fb86ce50</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">93/0.0.0/433e0ccc46f9880962cc2b120651897</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #800080; text-decoration-color: #800080\">66fbb2bee57a221866138fb9203c83519/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">cache-</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">c4ff947579e82159.arrow</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[2022-03-08 18:22:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Loading cached shuffled indices for      \u001b]8;id=805553;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b\\\u001b[2marrow_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=99911;file:///home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/datasets/arrow_dataset.py#2937\u001b\\\u001b[2m2937\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         dataset at \u001b[35m/home/ec2-user/.cache/hugging\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35mface/datasets/csv/default-402b02fb86ce50\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35m93/0.0.0/433e0ccc46f9880962cc2b120651897\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[35m66fbb2bee57a221866138fb9203c83519/\u001b[0m\u001b[95mcache-\u001b[0m \u001b[2m                     \u001b[0m\n",
       "\u001b[2;36m                      \u001b[0m         \u001b[95mc4ff947579e82159.arrow\u001b[0m                   \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading vinai/bertweet-base from cache or   <a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hf_finetune.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#135\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         Hugging Face hub                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading vinai/bertweet-base from cache or   \u001b]8;id=155791;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\u001b\\\u001b[2mhf_finetune.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149485;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#135\u001b\\\u001b[2m135\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         Hugging Face hub                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/vinai/bertweet-base/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/356366feedcea0917e30f7f235e1e062ffc2d28138445d5672a184be756c8686.a2b6026e688d1b19cebc0981d8f3a5b1668eabfda55b2c42049d5eac0bc8cb2d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"vinai/bertweet-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/vinai/bertweet-base/resolve/main/pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/transformers/4e07e2989cb95a6f63c704a7170b48e6e663cc203c05db424e47f4d75562cf0e.7b2adda243ecb4b085eb2d22ef1b2cd12a882a43bbb13a34c11e10f960b9bfc3\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2022-03-08 18:22:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running Population Based Training -         <a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hf_finetune.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#212\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         Hyperparams Search                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[2022-03-08 18:22:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running Population Based Training -         \u001b]8;id=670487;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py\u001b\\\u001b[2mhf_finetune.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=26225;file:///home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hf_finetune.py#212\u001b\\\u001b[2m212\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                      \u001b[0m         Hyperparams Search                          \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ray/tune/tune.py:422: UserWarning: Consider boosting PBT performance by enabling `reuse_actors` as well as implementing `reset_config` for Trainable.\n",
      "  \"Consider boosting PBT performance by enabling `reuse_actors` as \"\n",
      "2022-03-08 18:22:19,767\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,768\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,772\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,773\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,778\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,779\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,783\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,784\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,788\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,789\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,793\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,793\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,798\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,798\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,802\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "2022-03-08 18:22:19,803\tWARNING trial_runner.py:1454 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:19 (running for 00:00:00.17)\n",
      "Memory usage on this node: 5.1/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (8 PENDING)\n",
      "+------------------------+----------+-------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc   |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+-------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | PENDING  |       |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |       |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |       |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |       |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |       |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |       |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |       |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |       |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+-------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:25 (running for 00:00:05.24)\n",
      "Memory usage on this node: 7.1/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:25.743790775    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:25.795871515    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:25.958970289    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m   FutureWarning,\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:28.247219494    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb: Currently logged in as: chrisliew (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:28.442569932    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:28.474865871    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m E0308 18:22:28.516852871    7594 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:30 (running for 00:00:11.18)\n",
      "Memory usage on this node: 7.8/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m signal only works in main thread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb: Tracking run with wandb version 0.12.11\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb: Run data is saved locally in /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18/_objective_b0de0_00000_0_learning_rate=5e-05,num_train_epochs=5,warmup_steps=500,weight_decay=0.28521_2022-03-08_18-22-19/wandb/run-20220308_182228-23ncxeeg\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb: Syncing run generous-universe-29\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb:  View project at https://wandb.ai/chrisliew/huggingface\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m wandb:  View run at https://wandb.ai/chrisliew/huggingface/runs/23ncxeeg\n",
      "  0%|          | 0/160 [00:00<?, ?it/s]\n",
      "  1%|          | 1/160 [00:00<01:30,  1.75it/s]\n",
      "  1%|         | 2/160 [00:00<01:02,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:35 (running for 00:00:16.19)\n",
      "Memory usage on this node: 7.8/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 3/160 [00:01<00:53,  2.94it/s]\n",
      "  2%|         | 4/160 [00:01<00:48,  3.21it/s]\n",
      "  3%|         | 5/160 [00:01<00:45,  3.38it/s]\n",
      "  4%|         | 6/160 [00:01<00:44,  3.48it/s]\n",
      "  4%|         | 7/160 [00:02<00:43,  3.55it/s]\n",
      "  5%|         | 8/160 [00:02<00:42,  3.60it/s]\n",
      "  6%|         | 9/160 [00:02<00:41,  3.62it/s]\n",
      "  6%|         | 10/160 [00:03<00:41,  3.65it/s]\n",
      "  7%|         | 11/160 [00:03<00:40,  3.67it/s]\n",
      "  8%|         | 12/160 [00:03<00:40,  3.68it/s]\n",
      "  8%|         | 13/160 [00:03<00:39,  3.69it/s]\n",
      "  9%|         | 14/160 [00:04<00:39,  3.69it/s]\n",
      "  9%|         | 15/160 [00:04<00:39,  3.70it/s]\n",
      " 10%|         | 16/160 [00:04<00:38,  3.71it/s]\n",
      " 11%|         | 17/160 [00:04<00:38,  3.70it/s]\n",
      " 11%|        | 18/160 [00:05<00:38,  3.69it/s]\n",
      " 12%|        | 19/160 [00:05<00:38,  3.70it/s]\n",
      " 12%|        | 20/160 [00:05<00:37,  3.70it/s]\n",
      " 13%|        | 21/160 [00:05<00:37,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:40 (running for 00:00:21.21)\n",
      "Memory usage on this node: 7.8/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 22/160 [00:06<00:37,  3.69it/s]\n",
      " 14%|        | 23/160 [00:06<00:37,  3.67it/s]\n",
      " 15%|        | 24/160 [00:06<00:37,  3.64it/s]\n",
      " 16%|        | 25/160 [00:07<00:37,  3.64it/s]\n",
      " 16%|        | 26/160 [00:07<00:36,  3.66it/s]\n",
      " 17%|        | 27/160 [00:07<00:36,  3.66it/s]\n",
      " 18%|        | 28/160 [00:07<00:36,  3.66it/s]\n",
      " 18%|        | 29/160 [00:08<00:35,  3.66it/s]\n",
      " 19%|        | 30/160 [00:08<00:35,  3.67it/s]\n",
      " 19%|        | 31/160 [00:08<00:35,  3.67it/s]\n",
      " 20%|        | 32/160 [00:08<00:29,  4.33it/s]\n",
      " 21%|        | 33/160 [00:09<00:30,  4.13it/s]\n",
      " 21%|       | 34/160 [00:09<00:31,  3.99it/s]\n",
      " 22%|       | 35/160 [00:09<00:32,  3.90it/s]\n",
      " 22%|       | 36/160 [00:09<00:32,  3.82it/s]\n",
      " 23%|       | 37/160 [00:10<00:32,  3.79it/s]\n",
      " 24%|       | 38/160 [00:10<00:32,  3.78it/s]\n",
      " 24%|       | 39/160 [00:10<00:32,  3.76it/s]\n",
      " 25%|       | 40/160 [00:11<00:32,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:45 (running for 00:00:26.23)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 41/160 [00:11<00:31,  3.73it/s]\n",
      " 26%|       | 42/160 [00:11<00:31,  3.74it/s]\n",
      " 27%|       | 43/160 [00:11<00:31,  3.72it/s]\n",
      " 28%|       | 44/160 [00:12<00:31,  3.70it/s]\n",
      " 28%|       | 45/160 [00:12<00:31,  3.70it/s]\n",
      " 29%|       | 46/160 [00:12<00:30,  3.72it/s]\n",
      " 29%|       | 47/160 [00:12<00:30,  3.71it/s]\n",
      " 30%|       | 48/160 [00:13<00:30,  3.69it/s]\n",
      " 31%|       | 49/160 [00:13<00:30,  3.68it/s]\n",
      " 31%|      | 50/160 [00:13<00:29,  3.71it/s]\n",
      " 32%|      | 51/160 [00:13<00:29,  3.70it/s]\n",
      " 32%|      | 52/160 [00:14<00:29,  3.72it/s]\n",
      " 33%|      | 53/160 [00:14<00:28,  3.73it/s]\n",
      " 34%|      | 54/160 [00:14<00:28,  3.74it/s]\n",
      " 34%|      | 55/160 [00:15<00:28,  3.72it/s]\n",
      " 35%|      | 56/160 [00:15<00:27,  3.73it/s]\n",
      " 36%|      | 57/160 [00:15<00:27,  3.71it/s]\n",
      " 36%|      | 58/160 [00:15<00:27,  3.70it/s]\n",
      " 37%|      | 59/160 [00:16<00:27,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:51 (running for 00:00:31.25)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 60/160 [00:16<00:27,  3.66it/s]\n",
      " 38%|      | 61/160 [00:16<00:26,  3.68it/s]\n",
      " 39%|      | 62/160 [00:16<00:26,  3.69it/s]\n",
      " 39%|      | 63/160 [00:17<00:26,  3.66it/s]\n",
      " 40%|      | 64/160 [00:17<00:22,  4.36it/s]\n",
      " 41%|      | 65/160 [00:17<00:22,  4.17it/s]\n",
      " 41%|     | 66/160 [00:17<00:23,  4.01it/s]\n",
      " 42%|     | 67/160 [00:18<00:23,  3.93it/s]\n",
      " 42%|     | 68/160 [00:18<00:23,  3.85it/s]\n",
      " 43%|     | 69/160 [00:18<00:23,  3.80it/s]\n",
      " 44%|     | 70/160 [00:18<00:23,  3.78it/s]\n",
      " 44%|     | 71/160 [00:19<00:23,  3.77it/s]\n",
      " 45%|     | 72/160 [00:19<00:23,  3.77it/s]\n",
      " 46%|     | 73/160 [00:19<00:23,  3.77it/s]\n",
      " 46%|     | 74/160 [00:20<00:23,  3.73it/s]\n",
      " 47%|     | 75/160 [00:20<00:22,  3.73it/s]\n",
      " 48%|     | 76/160 [00:20<00:22,  3.72it/s]\n",
      " 48%|     | 77/160 [00:20<00:22,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:22:56 (running for 00:00:36.27)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 78/160 [00:21<00:22,  3.68it/s]\n",
      " 49%|     | 79/160 [00:21<00:22,  3.66it/s]\n",
      " 50%|     | 80/160 [00:21<00:21,  3.67it/s]\n",
      " 51%|     | 81/160 [00:21<00:21,  3.69it/s]\n",
      " 51%|    | 82/160 [00:22<00:21,  3.71it/s]\n",
      " 52%|    | 83/160 [00:22<00:20,  3.73it/s]\n",
      " 52%|    | 84/160 [00:22<00:20,  3.72it/s]\n",
      " 53%|    | 85/160 [00:23<00:20,  3.71it/s]\n",
      " 54%|    | 86/160 [00:23<00:20,  3.69it/s]\n",
      " 54%|    | 87/160 [00:23<00:19,  3.72it/s]\n",
      " 55%|    | 88/160 [00:23<00:19,  3.73it/s]\n",
      " 56%|    | 89/160 [00:24<00:18,  3.74it/s]\n",
      " 56%|    | 90/160 [00:24<00:18,  3.69it/s]\n",
      " 57%|    | 91/160 [00:24<00:18,  3.71it/s]\n",
      " 57%|    | 92/160 [00:24<00:18,  3.70it/s]\n",
      " 58%|    | 93/160 [00:25<00:18,  3.68it/s]\n",
      " 59%|    | 94/160 [00:25<00:17,  3.67it/s]\n",
      " 59%|    | 95/160 [00:25<00:17,  3.66it/s]\n",
      " 60%|    | 96/160 [00:25<00:14,  4.36it/s]\n",
      " 61%|    | 97/160 [00:26<00:15,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:01 (running for 00:00:41.29)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 98/160 [00:26<00:15,  3.97it/s]\n",
      " 62%|   | 99/160 [00:26<00:15,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m {'loss': 0.6258, 'learning_rate': 1e-05, 'epoch': 3.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 100/160 [00:27<00:19,  3.01it/s]\n",
      " 63%|   | 101/160 [00:27<00:18,  3.18it/s]\n",
      " 64%|   | 102/160 [00:27<00:17,  3.31it/s]\n",
      " 64%|   | 103/160 [00:27<00:16,  3.41it/s]\n",
      " 65%|   | 104/160 [00:28<00:16,  3.44it/s]\n",
      " 66%|   | 105/160 [00:28<00:15,  3.50it/s]\n",
      " 66%|   | 106/160 [00:28<00:15,  3.56it/s]\n",
      " 67%|   | 107/160 [00:29<00:14,  3.60it/s]\n",
      " 68%|   | 108/160 [00:29<00:14,  3.60it/s]\n",
      " 68%|   | 109/160 [00:29<00:14,  3.63it/s]\n",
      " 69%|   | 110/160 [00:29<00:13,  3.65it/s]\n",
      " 69%|   | 111/160 [00:30<00:13,  3.65it/s]\n",
      " 70%|   | 112/160 [00:30<00:13,  3.66it/s]\n",
      " 71%|   | 113/160 [00:30<00:12,  3.66it/s]\n",
      " 71%|  | 114/160 [00:31<00:12,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:06 (running for 00:00:46.31)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 115/160 [00:31<00:12,  3.67it/s]\n",
      " 72%|  | 116/160 [00:31<00:11,  3.67it/s]\n",
      " 73%|  | 117/160 [00:31<00:11,  3.67it/s]\n",
      " 74%|  | 118/160 [00:32<00:11,  3.66it/s]\n",
      " 74%|  | 119/160 [00:32<00:11,  3.66it/s]\n",
      " 75%|  | 120/160 [00:32<00:10,  3.66it/s]\n",
      " 76%|  | 121/160 [00:32<00:10,  3.65it/s]\n",
      " 76%|  | 122/160 [00:33<00:10,  3.65it/s]\n",
      " 77%|  | 123/160 [00:33<00:10,  3.65it/s]\n",
      " 78%|  | 124/160 [00:33<00:09,  3.63it/s]\n",
      " 78%|  | 125/160 [00:34<00:09,  3.64it/s]\n",
      " 79%|  | 126/160 [00:34<00:09,  3.65it/s]\n",
      " 79%|  | 127/160 [00:34<00:09,  3.65it/s]\n",
      " 80%|  | 128/160 [00:34<00:07,  4.33it/s]\n",
      " 81%|  | 129/160 [00:34<00:07,  4.12it/s]\n",
      " 81%| | 130/160 [00:35<00:07,  3.96it/s]\n",
      " 82%| | 131/160 [00:35<00:07,  3.86it/s]\n",
      " 82%| | 132/160 [00:35<00:07,  3.79it/s]\n",
      " 83%| | 133/160 [00:36<00:07,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:11 (running for 00:00:51.33)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 134/160 [00:36<00:06,  3.72it/s]\n",
      " 84%| | 135/160 [00:36<00:06,  3.69it/s]\n",
      " 85%| | 136/160 [00:36<00:06,  3.69it/s]\n",
      " 86%| | 137/160 [00:37<00:06,  3.67it/s]\n",
      " 86%| | 138/160 [00:37<00:06,  3.66it/s]\n",
      " 87%| | 139/160 [00:37<00:05,  3.67it/s]\n",
      " 88%| | 140/160 [00:37<00:05,  3.67it/s]\n",
      " 88%| | 141/160 [00:38<00:05,  3.67it/s]\n",
      " 89%| | 142/160 [00:38<00:04,  3.67it/s]\n",
      " 89%| | 143/160 [00:38<00:04,  3.66it/s]\n",
      " 90%| | 144/160 [00:39<00:04,  3.65it/s]\n",
      " 91%| | 145/160 [00:39<00:04,  3.65it/s]\n",
      " 91%|| 146/160 [00:39<00:03,  3.65it/s]\n",
      " 92%|| 147/160 [00:39<00:03,  3.65it/s]\n",
      " 92%|| 148/160 [00:40<00:03,  3.65it/s]\n",
      " 93%|| 149/160 [00:40<00:03,  3.65it/s]\n",
      " 94%|| 150/160 [00:40<00:02,  3.66it/s]\n",
      " 94%|| 151/160 [00:40<00:02,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:16 (running for 00:00:56.34)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 152/160 [00:41<00:02,  3.66it/s]\n",
      " 96%|| 153/160 [00:41<00:01,  3.65it/s]\n",
      " 96%|| 154/160 [00:41<00:01,  3.64it/s]\n",
      " 97%|| 155/160 [00:42<00:01,  3.64it/s]\n",
      " 98%|| 156/160 [00:42<00:01,  3.65it/s]\n",
      " 98%|| 157/160 [00:42<00:00,  3.66it/s]\n",
      " 99%|| 158/160 [00:42<00:00,  3.66it/s]\n",
      " 99%|| 159/160 [00:43<00:00,  3.65it/s]\n",
      "100%|| 160/160 [00:43<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m {'train_runtime': 49.9678, 'train_samples_per_second': 100.065, 'train_steps_per_second': 3.202, 'train_loss': 0.5769810795783996, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]\n",
      "  9%|         | 3/32 [00:00<00:01, 19.49it/s]\n",
      " 16%|        | 5/32 [00:00<00:01, 15.68it/s]\n",
      " 22%|       | 7/32 [00:00<00:01, 14.46it/s]\n",
      " 28%|       | 9/32 [00:00<00:01, 13.89it/s]\n",
      " 34%|      | 11/32 [00:00<00:01, 13.52it/s]\n",
      " 41%|      | 13/32 [00:00<00:01, 13.31it/s]\n",
      " 47%|     | 15/32 [00:01<00:01, 13.20it/s]\n",
      " 53%|    | 17/32 [00:01<00:01, 13.11it/s]\n",
      " 59%|    | 19/32 [00:01<00:00, 13.06it/s]\n",
      " 66%|   | 21/32 [00:01<00:00, 13.01it/s]\n",
      " 72%|  | 23/32 [00:01<00:00, 13.01it/s]\n",
      " 78%|  | 25/32 [00:01<00:00, 12.98it/s]\n",
      " 84%| | 27/32 [00:02<00:00, 12.89it/s]\n",
      " 91%| | 29/32 [00:02<00:00, 12.90it/s]\n",
      " 97%|| 31/32 [00:02<00:00, 12.94it/s]/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m   warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m   warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "100%|| 32/32 [00:02<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:21 (running for 00:01:01.37)\n",
      "Memory usage on this node: 8.0/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------|\n",
      "| _objective_b0de0_00000 | RUNNING  | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00001 | PENDING  |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00002 | PENDING  |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |\n",
      "| _objective_b0de0_00003 | PENDING  |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00004 | PENDING  |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |\n",
      "| _objective_b0de0_00005 | PENDING  |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |\n",
      "| _objective_b0de0_00006 | PENDING  |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |\n",
      "| _objective_b0de0_00007 | PENDING  |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |\n",
      "+------------------------+----------+--------------------+----------+-----------+-------+----------------+--------------+\n",
      "\n",
      "\n",
      "Result for _objective_b0de0_00000:\n",
      "  date: 2022-03-08_18-23-24\n",
      "  done: true\n",
      "  epoch: 5.0\n",
      "  eval_acc: 0.786\n",
      "  eval_loss: 0.45892900228500366\n",
      "  eval_runtime: 2.422\n",
      "  eval_samples_per_second: 412.888\n",
      "  eval_steps_per_second: 13.212\n",
      "  experiment_id: f7b96a79a6e3486b9054eda4b3575e92\n",
      "  hostname: ip-172-16-56-108\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.16.56.108\n",
      "  objective: 0.786\n",
      "  pid: 7142\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.48448729515076\n",
      "  time_this_iter_s: 63.48448729515076\n",
      "  time_total_s: 63.48448729515076\n",
      "  timestamp: 1646763804\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: b0de0_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m   warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:26 (running for 00:01:06.37)\n",
      "Memory usage on this node: 5.2/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (7 PENDING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | PENDING    |                    |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(_objective pid=7142)\u001b[0m   len(cache))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:32 (running for 00:01:12.25)\n",
      "Memory usage on this node: 7.0/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (6 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | RUNNING    | 172.16.56.108:7143 |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:32.789227916    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:32.842908851    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:33.007065207    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m   FutureWarning,\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:35.304294569    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb: Currently logged in as: chrisliew (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:35.539177076    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:35.571811811    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m E0308 18:23:35.613678230    8336 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:37 (running for 00:01:17.27)\n",
      "Memory usage on this node: 7.8/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (6 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | RUNNING    | 172.16.56.108:7143 |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:42 (running for 00:01:22.29)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (6 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | RUNNING    | 172.16.56.108:7143 |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb: Tracking run with wandb version 0.12.11\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb: Run data is saved locally in /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18/_objective_b0de0_00001_1_learning_rate=5e-05,num_train_epochs=2,warmup_steps=50,weight_decay=0.046806_2022-03-08_18-22-19/wandb/run-20220308_182335-1upfm4bk\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb: Syncing run different-voice-30\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb:  View project at https://wandb.ai/chrisliew/huggingface\n",
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m wandb:  View run at https://wandb.ai/chrisliew/huggingface/runs/1upfm4bk\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=7143)\u001b[0m signal only works in main thread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/64 [00:00<00:32,  1.92it/s]\n",
      "  3%|         | 2/64 [00:00<00:23,  2.65it/s]\n",
      "  5%|         | 3/64 [00:01<00:20,  3.01it/s]\n",
      "  6%|         | 4/64 [00:01<00:18,  3.23it/s]\n",
      "  8%|         | 5/64 [00:01<00:17,  3.38it/s]\n",
      "  9%|         | 6/64 [00:01<00:16,  3.47it/s]\n",
      " 11%|         | 7/64 [00:02<00:16,  3.54it/s]\n",
      " 12%|        | 8/64 [00:02<00:15,  3.57it/s]\n",
      " 14%|        | 9/64 [00:02<00:15,  3.59it/s]\n",
      " 16%|        | 10/64 [00:02<00:14,  3.60it/s]\n",
      " 17%|        | 11/64 [00:03<00:14,  3.61it/s]\n",
      " 19%|        | 12/64 [00:03<00:14,  3.63it/s]\n",
      " 20%|        | 13/64 [00:03<00:14,  3.64it/s]\n",
      " 22%|       | 14/64 [00:04<00:13,  3.64it/s]\n",
      " 23%|       | 15/64 [00:04<00:13,  3.64it/s]\n",
      " 25%|       | 16/64 [00:04<00:13,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:47 (running for 00:01:27.31)\n",
      "Memory usage on this node: 7.8/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (6 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | RUNNING    | 172.16.56.108:7143 |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 17/64 [00:04<00:12,  3.66it/s]\n",
      " 28%|       | 18/64 [00:05<00:12,  3.64it/s]\n",
      " 30%|       | 19/64 [00:05<00:12,  3.66it/s]\n",
      " 31%|      | 20/64 [00:05<00:12,  3.66it/s]\n",
      " 33%|      | 21/64 [00:06<00:11,  3.65it/s]\n",
      " 34%|      | 22/64 [00:06<00:11,  3.67it/s]\n",
      " 36%|      | 23/64 [00:06<00:11,  3.67it/s]\n",
      " 38%|      | 24/64 [00:06<00:10,  3.68it/s]\n",
      " 39%|      | 25/64 [00:07<00:10,  3.67it/s]\n",
      " 41%|      | 26/64 [00:07<00:10,  3.67it/s]\n",
      " 42%|     | 27/64 [00:07<00:10,  3.67it/s]\n",
      " 44%|     | 28/64 [00:07<00:09,  3.69it/s]\n",
      " 45%|     | 29/64 [00:08<00:09,  3.68it/s]\n",
      " 47%|     | 30/64 [00:08<00:09,  3.68it/s]\n",
      " 48%|     | 31/64 [00:08<00:08,  3.70it/s]\n",
      " 50%|     | 32/64 [00:08<00:07,  4.38it/s]\n",
      " 52%|    | 33/64 [00:09<00:07,  4.15it/s]\n",
      " 53%|    | 34/64 [00:09<00:07,  3.99it/s]\n",
      " 55%|    | 35/64 [00:09<00:07,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-08 18:23:52 (running for 00:01:32.33)\n",
      "Memory usage on this node: 7.7/60.0 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/35.43 GiB heap, 0.0/17.71 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/ec2-user/SageMaker/Crypto-Uncertainty-Index/nlp/hedge_classifier/hyper_tuning/ray_results/tune_hf_pbt_2022-03-08T18:22:18\n",
      "Number of trials: 8/8 (6 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "| Trial name             | status     | loc                |   warmup |   w_decay |    lr |   train_bs/gpu |   num_epochs |   eval_acc |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------|\n",
      "| _objective_b0de0_00001 | RUNNING    | 172.16.56.108:7143 |       50 | 0.0468056 | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00002 | PENDING    |                    |      500 | 0.137775  | 1e-05 |             32 |            4 |            |             |         |                      |\n",
      "| _objective_b0de0_00003 | PENDING    |                    |      500 | 0.0169235 | 2e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00004 | PENDING    |                    |      100 | 0.0545475 | 1e-05 |             32 |            3 |            |             |         |                      |\n",
      "| _objective_b0de0_00005 | PENDING    |                    |       50 | 0.183496  | 1e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00006 | PENDING    |                    |       50 | 0.157432  | 5e-05 |             32 |            2 |            |             |         |                      |\n",
      "| _objective_b0de0_00007 | PENDING    |                    |      100 | 0.0876434 | 5e-05 |             32 |            5 |            |             |         |                      |\n",
      "| _objective_b0de0_00000 | TERMINATED | 172.16.56.108:7142 |      500 | 0.285214  | 5e-05 |             32 |            5 |      0.786 |    0.458929 |       5 |                    1 |\n",
      "+------------------------+------------+--------------------+----------+-----------+-------+----------------+--------------+------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 36/64 [00:09<00:07,  3.83it/s]\n",
      " 58%|    | 37/64 [00:10<00:07,  3.76it/s]\n",
      " 59%|    | 38/64 [00:10<00:06,  3.76it/s]\n",
      " 61%|    | 39/64 [00:10<00:06,  3.70it/s]\n",
      " 62%|   | 40/64 [00:11<00:06,  3.67it/s]\n",
      " 64%|   | 41/64 [00:11<00:06,  3.67it/s]\n",
      " 66%|   | 42/64 [00:11<00:06,  3.66it/s]\n",
      " 67%|   | 43/64 [00:11<00:05,  3.64it/s]\n",
      " 69%|   | 44/64 [00:12<00:05,  3.64it/s]\n",
      " 70%|   | 45/64 [00:12<00:05,  3.64it/s]\n",
      " 72%|  | 46/64 [00:12<00:04,  3.62it/s]\n",
      " 73%|  | 47/64 [00:12<00:04,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "best_result = train_pbt_hf_clf(\n",
    "    model_name=model_name,\n",
    "    train_data_dir=train_data_dir,\n",
    "    model_save_dir=model_save_dir,\n",
    "    num_labels=num_labels,\n",
    "    text_col=text_col,\n",
    "    wandb_args=wandb_args,\n",
    "    train_data_file_type=train_data_file_type,\n",
    "    sample_data_size=sample_data_size,\n",
    "    num_cpus_per_trial=num_cpus_per_trial,\n",
    "    num_gpus_per_trial=num_gpus_per_trial,\n",
    "    smoke_test=smoke_test,\n",
    "    ray_address=ray_address,\n",
    "    ray_num_trials=ray_num_trials,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2c946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
